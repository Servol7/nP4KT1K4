{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9064a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208cc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(row):\n",
    "# getting loading_* params\n",
    "    lw = row['data_result']['cargo_space']['loading_size']['width']\n",
    "    lh = row['data_result']['cargo_space']['loading_size']['height']\n",
    "    ll = row['data_result']['cargo_space']['loading_size']['length']\n",
    "    \n",
    "# normalizing box size params\n",
    "    w = np.array([x['size']['width'] for x in row['data_result']['boxes']]) / lw\n",
    "    h = np.array([x['size']['height'] for x in row['data_result']['boxes']]) / lh\n",
    "    l = np.array([x['size']['length'] for x in row['data_result']['boxes']]) / ll\n",
    "    \n",
    "    # getting volume\n",
    "    v = w * h * l\n",
    "#     ids = np.array([x['id'] for x in row['data_result']['boxes']])\n",
    "\n",
    "# getting other params\n",
    "    t = np.array([int(x['turnover']) for x in row['data_result']['boxes']])\n",
    "    s = np.array([int(x['stacking']) for x in row['data_result']['boxes']])\n",
    "    \n",
    "# make custom params\n",
    "    w_t = w[t == 1]\n",
    "    h_t = h[t == 1]\n",
    "    l_t = l[t == 1]\n",
    "    v_t = w_t * h_t * l_t \n",
    "    w_nt = w[t == 0]\n",
    "    h_nt = h[t == 0]\n",
    "    l_nt = l[t == 0]\n",
    "    v_nt = w_nt * h_nt * l_nt\n",
    "\n",
    "    w_s = w[s == 1]\n",
    "    h_s = h[s == 1]\n",
    "    l_s = l[s == 1]\n",
    "    v_s = w_s * h_s * l_s\n",
    "    w_ns = w[s == 0]\n",
    "    h_ns = h[s == 0]\n",
    "    l_ns = l[s == 0]\n",
    "    v_ns = w_ns * h_ns * l_ns\n",
    "\n",
    "\n",
    "# getting labels\n",
    "    d = row['data_result']['cargo_space']['calculation_info']['density_percent'] / 100\n",
    "    \n",
    "# used quantiles\n",
    "    qs = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "    return {\n",
    "#         \"n\": len(row['data_result']['boxes']),\n",
    "# various aggregated statistics of sizes, volumes and other params\n",
    "        \"mean_width\": w.mean(),\n",
    "        \"mean_height\": h.mean(),\n",
    "        \"mean_length\": l.mean(),\n",
    "        \"mean_volume\": v.mean(),\n",
    "        \"std_width\" : w.std(),\n",
    "        \"std_height\" : h.std(),\n",
    "        \"std_length\" : l.std(),\n",
    "        \"std_volume\" : v.std(),\n",
    "        \"sum_width\": w.sum(),\n",
    "        \"sum_height\": h.sum(),\n",
    "        \"sum_length\": l.sum(),\n",
    "        \"sum_volume\": v.sum(),\n",
    "        \"mean_turnover\": t.mean(),\n",
    "        \"mean_stacking\": s.mean(),\n",
    "        \n",
    "        \"mean_width_turnover\": w_t.mean(),\n",
    "        \"mean_height_turnover\": h_t.mean(),\n",
    "        \"mean_length_turnover\": l_t.mean(),\n",
    "        \"mean_volume_turnover\": v_t.mean(),\n",
    "        \"std_width_turnover\" : w_t.std(),\n",
    "        \"std_height_turnover\" : h_t.std(),\n",
    "        \"std_length_turnover\" : l_t.std(),\n",
    "        \"std_volume_turnover\" : v_t.std(),\n",
    "        \"sum_width_turnover\": w_t.sum(),\n",
    "        \"sum_height_turnover\": h_t.sum(),\n",
    "        \"sum_length_turnover\": l_t.sum(),\n",
    "        \"sum_volume_turnover\": v_t.sum(),\n",
    "        \n",
    "        \"mean_width_no_turnover\": w_nt.mean(),\n",
    "        \"mean_height_no_turnover\": h_nt.mean(),\n",
    "        \"mean_length_no_turnover\": l_nt.mean(),\n",
    "        \"mean_volume_no_turnover\": v_nt.mean(),\n",
    "        \"std_width_no_turnover\" : w_nt.std(),\n",
    "        \"std_height_no_turnover\" : h_nt.std(),\n",
    "        \"std_length_no_turnover\" : l_nt.std(),\n",
    "        \"std_volume_no_turnover\" : v_nt.std(),\n",
    "        \"sum_width_no_turnover\": w_nt.sum(),\n",
    "        \"sum_height_no_turnover\": h_nt.sum(),\n",
    "        \"sum_length_no_turnover\": l_nt.sum(),\n",
    "        \"sum_volume_no_turnover\": v_nt.sum(),\n",
    "        \n",
    "        \"mean_width_stacking\": w_s.mean(),\n",
    "        \"mean_height_stacking\": h_s.mean(),\n",
    "        \"mean_length_stacking\": l_s.mean(),\n",
    "        \"mean_volume_stacking\": v_s.mean(),        \n",
    "        \"std_width_stacking\" : w_s.std(),\n",
    "        \"std_height_stacking\" : h_s.std(),\n",
    "        \"std_length_stacking\" : l_s.std(),\n",
    "        \"std_volume_stacking\" : v_s.std(),\n",
    "        \"sum_width_stacking\": w_s.sum(),\n",
    "        \"sum_height_stacking\": h_s.sum(),\n",
    "        \"sum_length_stacking\": l_s.sum(),\n",
    "        \"sum_volume_stacking\": v_s.sum(),\n",
    "        \n",
    "        \"mean_width_no_stacking\": w_ns.mean(),\n",
    "        \"mean_height_no_stacking\": h_ns.mean(),\n",
    "        \"mean_length_no_stacking\": l_ns.mean(),\n",
    "        \"mean_volume_no_stacking\": v_ns.mean(),\n",
    "        \"std_width_no_stacking\" : w_ns.std(),\n",
    "        \"std_height_no_stacking\" : h_ns.std(),\n",
    "        \"std_length_no_stacking\" : l_ns.std(),\n",
    "        \"std_volume_no_stacking\" : v_ns.std(),\n",
    "        \"sum_width_no_stacking\": w_ns.sum(),\n",
    "        \"sum_height_no_stacking\": h_ns.sum(),\n",
    "        \"sum_length_no_stacking\": l_ns.sum(),\n",
    "        \"sum_volume_no_stacking\": v_ns.sum(),\n",
    "        **{\n",
    "            \"width_p{}\".format(int(q * 100)): np.quantile(w, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"heigth_p{}\".format(int(q * 100)): np.quantile(h, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"length_p{}\".format(int(q * 100)): np.quantile(l, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"volume_p{}\".format(int(q * 100)): np.quantile(v, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"width_turning_p{}\".format(int(q * 100)): -1 if len(w_t) == 0 else np.quantile(w_t, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"heigth_turning_p{}\".format(int(q * 100)): -1 if len(h_t) == 0 else np.quantile(h_t, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"length_turning_p{}\".format(int(q * 100)): -1 if len(l_t) == 0 else np.quantile(l_t, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"volume_turning_p{}\".format(int(q * 100)): -1 if len(v_t) == 0 else np.quantile(v_t, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"width_stacking_p{}\".format(int(q * 100)): -1 if len(w_s) == 0 else np.quantile(w_s, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"heigth_stacking_p{}\".format(int(q * 100)): -1 if len(h_s) == 0 else np.quantile(h_s, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"length_stacking_p{}\".format(int(q * 100)): -1 if len(l_s) == 0 else np.quantile(l_s, q) for q in qs\n",
    "        },\n",
    "        **{\n",
    "            \"volume_stacking_p{}\".format(int(q * 100)): -1 if len(v_s) == 0 else np.quantile(v_s, q) for q in qs\n",
    "        },\n",
    "#         \"loading_width\": lw,\n",
    "#         \"loading_height\": lh,\n",
    "#         \"loading_length\": ll,\n",
    "        \n",
    "# labels\n",
    "        \"density_percent\": d,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b30a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distrib(x):\n",
    "# used for bootstrapping\n",
    "    return np.random.normal(x/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b708e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(row):\n",
    "# used for increasing dataset size\n",
    "    row['data_result']['cargo_space']['loading_size']['width'] += distrib(row['data_result']['cargo_space']['loading_size']['width'])\n",
    "    row['data_result']['cargo_space']['loading_size']['height'] += distrib(row['data_result']['cargo_space']['loading_size']['height'])\n",
    "    row['data_result']['cargo_space']['loading_size']['length'] += distrib(row['data_result']['cargo_space']['loading_size']['length'])\n",
    "    \n",
    "#     for i in range(len(row['data_result']['boxes'])):\n",
    "#         row['data_result']['boxes'][i]['size']['width'] += distrib(row['data_result']['boxes'][i]['size']['width'])\n",
    "#         row['data_result']['boxes'][i]['size']['height'] += distrib(row['data_result']['boxes'][i]['size']['height'])\n",
    "#         row['data_result']['boxes'][i]['size']['length'] += distrib(row['data_result']['boxes'][i]['size']['length'])\n",
    "    \n",
    "    return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a546ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_width</th>\n",
       "      <th>mean_height</th>\n",
       "      <th>mean_length</th>\n",
       "      <th>mean_volume</th>\n",
       "      <th>std_width</th>\n",
       "      <th>std_height</th>\n",
       "      <th>std_length</th>\n",
       "      <th>std_volume</th>\n",
       "      <th>sum_width</th>\n",
       "      <th>sum_height</th>\n",
       "      <th>...</th>\n",
       "      <th>length_stacking_p60</th>\n",
       "      <th>length_stacking_p80</th>\n",
       "      <th>length_stacking_p100</th>\n",
       "      <th>volume_stacking_p0</th>\n",
       "      <th>volume_stacking_p20</th>\n",
       "      <th>volume_stacking_p40</th>\n",
       "      <th>volume_stacking_p60</th>\n",
       "      <th>volume_stacking_p80</th>\n",
       "      <th>volume_stacking_p100</th>\n",
       "      <th>density_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160545</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.02278</td>\n",
       "      <td>0.046782</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>43.347088</td>\n",
       "      <td>23.290174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186169</td>\n",
       "      <td>0.212788</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.817642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160545</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.02278</td>\n",
       "      <td>0.046782</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>43.347088</td>\n",
       "      <td>23.290174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186169</td>\n",
       "      <td>0.212788</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.817642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.313951</td>\n",
       "      <td>0.723633</td>\n",
       "      <td>0.156861</td>\n",
       "      <td>0.035636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337171</td>\n",
       "      <td>12.301762</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313951</td>\n",
       "      <td>0.723633</td>\n",
       "      <td>0.156861</td>\n",
       "      <td>0.035636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337171</td>\n",
       "      <td>12.301762</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341128</td>\n",
       "      <td>0.160328</td>\n",
       "      <td>0.339351</td>\n",
       "      <td>0.019207</td>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.02732</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>11.257229</td>\n",
       "      <td>5.290818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343314</td>\n",
       "      <td>0.408707</td>\n",
       "      <td>0.408707</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.740278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_width  mean_height  mean_length  mean_volume  std_width  std_height  \\\n",
       "0    0.160545     0.086260     0.175225     0.002852   0.055125     0.02278   \n",
       "1    0.160545     0.086260     0.175225     0.002852   0.055125     0.02278   \n",
       "2    0.313951     0.723633     0.156861     0.035636   0.000000     0.00000   \n",
       "3    0.313951     0.723633     0.156861     0.035636   0.000000     0.00000   \n",
       "4    0.341128     0.160328     0.339351     0.019207   0.050023     0.02732   \n",
       "\n",
       "   std_length  std_volume  sum_width  sum_height  ...  length_stacking_p60  \\\n",
       "0    0.046782    0.002357  43.347088   23.290174  ...             0.186169   \n",
       "1    0.046782    0.002357  43.347088   23.290174  ...             0.186169   \n",
       "2    0.000000    0.000000   5.337171   12.301762  ...            -1.000000   \n",
       "3    0.000000    0.000000   5.337171   12.301762  ...            -1.000000   \n",
       "4    0.059937    0.007002  11.257229    5.290818  ...             0.343314   \n",
       "\n",
       "   length_stacking_p80  length_stacking_p100  volume_stacking_p0  \\\n",
       "0             0.212788              0.324980            0.000589   \n",
       "1             0.212788              0.324980            0.000589   \n",
       "2            -1.000000             -1.000000           -1.000000   \n",
       "3            -1.000000             -1.000000           -1.000000   \n",
       "4             0.408707              0.408707            0.009513   \n",
       "\n",
       "   volume_stacking_p20  volume_stacking_p40  volume_stacking_p60  \\\n",
       "0             0.000910             0.001289             0.003574   \n",
       "1             0.000910             0.001289             0.003574   \n",
       "2            -1.000000            -1.000000            -1.000000   \n",
       "3            -1.000000            -1.000000            -1.000000   \n",
       "4             0.009989             0.018730             0.020335   \n",
       "\n",
       "   volume_stacking_p80  volume_stacking_p100  density_percent  \n",
       "0             0.003691              0.015735         0.817642  \n",
       "1             0.003691              0.015735         0.817642  \n",
       "2            -1.000000             -1.000000         0.944444  \n",
       "3            -1.000000             -1.000000         0.944444  \n",
       "4             0.026757              0.026757         0.740278  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"./ALGORITM\"\n",
    "\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "data = []\n",
    "test_data = []\n",
    "test_size = 0.4\n",
    "\n",
    "# reading all json files and putting info into csv with pandas\n",
    "for file in file_list:\n",
    "    if file.endswith('.json'):\n",
    "        path = os.path.join(folder_path, file)\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            raw = json.load(f)\n",
    "            if np.random.random() > test_size:\n",
    "                # for train\n",
    "                data.append(data_preparation(bootstrap(raw)))\n",
    "                data.append(data_preparation(raw))\n",
    "            else:\n",
    "                # for test\n",
    "                test_data.append(data_preparation(raw))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# fill empty\n",
    "df[df.isna()] = -1\n",
    "df.to_csv(\"data_custom_train.csv\", index=False)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "# fill empty\n",
    "df_test[df_test.isna()] = -1\n",
    "df_test.to_csv(\"data_custom_test.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3495e3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_width</th>\n",
       "      <th>mean_height</th>\n",
       "      <th>mean_length</th>\n",
       "      <th>mean_volume</th>\n",
       "      <th>std_width</th>\n",
       "      <th>std_height</th>\n",
       "      <th>std_length</th>\n",
       "      <th>std_volume</th>\n",
       "      <th>sum_width</th>\n",
       "      <th>sum_height</th>\n",
       "      <th>...</th>\n",
       "      <th>length_stacking_p60</th>\n",
       "      <th>length_stacking_p80</th>\n",
       "      <th>length_stacking_p100</th>\n",
       "      <th>volume_stacking_p0</th>\n",
       "      <th>volume_stacking_p20</th>\n",
       "      <th>volume_stacking_p40</th>\n",
       "      <th>volume_stacking_p60</th>\n",
       "      <th>volume_stacking_p80</th>\n",
       "      <th>volume_stacking_p100</th>\n",
       "      <th>density_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160545</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.02278</td>\n",
       "      <td>0.046782</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>43.347088</td>\n",
       "      <td>23.290174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186169</td>\n",
       "      <td>0.212788</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.817642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160545</td>\n",
       "      <td>0.086260</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.02278</td>\n",
       "      <td>0.046782</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>43.347088</td>\n",
       "      <td>23.290174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186169</td>\n",
       "      <td>0.212788</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.817642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.313951</td>\n",
       "      <td>0.723633</td>\n",
       "      <td>0.156861</td>\n",
       "      <td>0.035636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337171</td>\n",
       "      <td>12.301762</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313951</td>\n",
       "      <td>0.723633</td>\n",
       "      <td>0.156861</td>\n",
       "      <td>0.035636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.337171</td>\n",
       "      <td>12.301762</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341128</td>\n",
       "      <td>0.160328</td>\n",
       "      <td>0.339351</td>\n",
       "      <td>0.019207</td>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.02732</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>11.257229</td>\n",
       "      <td>5.290818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343314</td>\n",
       "      <td>0.408707</td>\n",
       "      <td>0.408707</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.740278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_width  mean_height  mean_length  mean_volume  std_width  std_height  \\\n",
       "0    0.160545     0.086260     0.175225     0.002852   0.055125     0.02278   \n",
       "1    0.160545     0.086260     0.175225     0.002852   0.055125     0.02278   \n",
       "2    0.313951     0.723633     0.156861     0.035636   0.000000     0.00000   \n",
       "3    0.313951     0.723633     0.156861     0.035636   0.000000     0.00000   \n",
       "4    0.341128     0.160328     0.339351     0.019207   0.050023     0.02732   \n",
       "\n",
       "   std_length  std_volume  sum_width  sum_height  ...  length_stacking_p60  \\\n",
       "0    0.046782    0.002357  43.347088   23.290174  ...             0.186169   \n",
       "1    0.046782    0.002357  43.347088   23.290174  ...             0.186169   \n",
       "2    0.000000    0.000000   5.337171   12.301762  ...            -1.000000   \n",
       "3    0.000000    0.000000   5.337171   12.301762  ...            -1.000000   \n",
       "4    0.059937    0.007002  11.257229    5.290818  ...             0.343314   \n",
       "\n",
       "   length_stacking_p80  length_stacking_p100  volume_stacking_p0  \\\n",
       "0             0.212788              0.324980            0.000589   \n",
       "1             0.212788              0.324980            0.000589   \n",
       "2            -1.000000             -1.000000           -1.000000   \n",
       "3            -1.000000             -1.000000           -1.000000   \n",
       "4             0.408707              0.408707            0.009513   \n",
       "\n",
       "   volume_stacking_p20  volume_stacking_p40  volume_stacking_p60  \\\n",
       "0             0.000910             0.001289             0.003574   \n",
       "1             0.000910             0.001289             0.003574   \n",
       "2            -1.000000            -1.000000            -1.000000   \n",
       "3            -1.000000            -1.000000            -1.000000   \n",
       "4             0.009989             0.018730             0.020335   \n",
       "\n",
       "   volume_stacking_p80  volume_stacking_p100  density_percent  \n",
       "0             0.003691              0.015735         0.817642  \n",
       "1             0.003691              0.015735         0.817642  \n",
       "2            -1.000000             -1.000000         0.944444  \n",
       "3            -1.000000             -1.000000         0.944444  \n",
       "4             0.026757              0.026757         0.740278  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d93f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
